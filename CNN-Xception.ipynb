{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "from PIL import Image\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.applications.xception import Xception\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "PATH = \"awe\"\n",
    "TRAIN_PATH = \"TrainData\"\n",
    "total_subjects = 100\n",
    "epochs = 50 \n",
    "img_size = 200\n",
    "          \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * 2 of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 2)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(mode): \n",
    "    total_images = []\n",
    "    label =[]\n",
    "    mode_path = os.path.join(PATH,mode)  # mode path -> awe/TrainData\n",
    "    subjects = os.listdir(mode_path)  # \n",
    "    \n",
    "    for subject in subjects:\n",
    "        image_path  = os.path.join(mode_path,subject)\n",
    "        images = os.listdir(image_path)\n",
    "        for image in images:\n",
    "            if(image.endswith(\".png\")):\n",
    "                file = os.path.join(image_path,image)\n",
    "                total_images.append(cv2.resize(cv2.imread(file),(200,200)))\n",
    "                label.append(int(subject))\n",
    "    total_images = np.array(total_images)\n",
    "    label = np.array(label)\n",
    "    return total_images , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,label = dataset('TrainData')\n",
    "\n",
    "def split_data(data,label,valid_len):\n",
    "    valid_len = int(valid_len*len(data)/100)\n",
    "    return (data[0:len(data)-valid_len],label[0:len(data)-valid_len],\n",
    "            data[len(data)-valid_len:len(data)],label[len(data)-valid_len:len(data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 200, 200, 3)\n",
      "(200, 200, 200, 3)\n",
      "(800,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_valid,y_valid = split_data(train,label,20)\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, total_subjects+1,dtype='int32')\n",
    "y_valid = keras.utils.to_categorical(y_valid, total_subjects+1,dtype='int32')\n",
    "y_train = y_train[:,0:total_subjects]\n",
    "y_valid = y_valid[:,0:total_subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 99, 99, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 99, 99, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 99, 99, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 97, 97, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 97, 97, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 97, 97, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 97, 97, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 97, 97, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 97, 97, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 97, 97, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 97, 97, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 49, 49, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 49, 49, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 49, 49, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 49, 49, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 49, 49, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 49, 49, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 49, 49, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 49, 49, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 49, 49, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 49, 49, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 25, 25, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 25, 25, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 25, 25, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 25, 25, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 25, 25, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 25, 25, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 25, 25, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 25, 25, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 25, 25, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 13, 13, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 13, 13, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 13, 13, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 13, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 13, 13, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 13, 13, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 13, 13, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 13, 13, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 13, 13, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 13, 13, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 13, 13, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 13, 13, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 13, 13, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 13, 13, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 13, 13, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 13, 13, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 13, 13, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 13, 13, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 13, 13, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 13, 13, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 13, 13, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 13, 13, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 13, 13, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 13, 13, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 13, 13, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 13, 13, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 13, 13, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 13, 13, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 13, 13, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 13, 13, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 13, 13, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 13, 13, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 13, 13, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 13, 13, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 13, 13, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 13, 13, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 13, 13, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 13, 13, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 13, 13, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 13, 13, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 13, 13, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 13, 13, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 13, 13, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 13, 13, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 13, 13, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 13, 13, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 13, 13, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 13, 13, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          204900      global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 21,066,380\n",
      "Trainable params: 21,011,852\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_modelX = tf.keras.applications.Xception(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(x_train[0].shape))\n",
    "\n",
    "#base_modelX.trainable = False\n",
    "#inputs = keras.Input(shape=(img_size, img_size, 3))\n",
    "#x = base_modelX(inputs, training=False)\n",
    "\n",
    "x= base_modelX.output\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = keras.layers.Dense(total_subjects,activation='softmax')(x)\n",
    "\n",
    "modelX = keras.Model(base_modelX.input, outputs)\n",
    "modelX.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer in base_modelX.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelX.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 11s 519ms/step - loss: 97.6480 - accuracy: 0.0111 - val_loss: 89.3819 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 3s 244ms/step - loss: 99.7803 - accuracy: 0.0087 - val_loss: 89.1972 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 3s 230ms/step - loss: 96.7317 - accuracy: 0.0126 - val_loss: 89.0088 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 3s 230ms/step - loss: 96.2326 - accuracy: 0.0129 - val_loss: 88.8191 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 3s 230ms/step - loss: 97.5408 - accuracy: 0.0143 - val_loss: 88.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 3s 232ms/step - loss: 98.4567 - accuracy: 0.0112 - val_loss: 88.4314 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 3s 232ms/step - loss: 96.4792 - accuracy: 0.0082 - val_loss: 88.2353 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 3s 232ms/step - loss: 96.0290 - accuracy: 0.0095 - val_loss: 88.0367 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 3s 232ms/step - loss: 94.6587 - accuracy: 0.0162 - val_loss: 87.8357 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 3s 233ms/step - loss: 93.3385 - accuracy: 0.0118 - val_loss: 87.6318 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 3s 233ms/step - loss: 94.2271 - accuracy: 0.0131 - val_loss: 87.4259 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 94.9663 - accuracy: 0.0140 - val_loss: 87.2190 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 3s 233ms/step - loss: 93.4367 - accuracy: 0.0158 - val_loss: 87.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 3s 233ms/step - loss: 93.5943 - accuracy: 0.0160 - val_loss: 86.7981 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 93.3138 - accuracy: 0.0133 - val_loss: 86.5847 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 90.7191 - accuracy: 0.0175 - val_loss: 86.3692 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 93.2394 - accuracy: 0.0108 - val_loss: 86.1532 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 92.9030 - accuracy: 0.0110 - val_loss: 85.9355 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 92.2181 - accuracy: 0.0156 - val_loss: 85.7167 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 93.6428 - accuracy: 0.0106 - val_loss: 85.4944 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 92.1386 - accuracy: 0.0125 - val_loss: 85.2705 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 88.6417 - accuracy: 0.0152 - val_loss: 85.0448 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 90.8931 - accuracy: 0.0123 - val_loss: 84.8181 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 90.8722 - accuracy: 0.0132 - val_loss: 84.5893 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 88.5374 - accuracy: 0.0120 - val_loss: 84.3578 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 89.2256 - accuracy: 0.0096 - val_loss: 84.1240 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 89.1222 - accuracy: 0.0162 - val_loss: 83.8902 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 87.4395 - accuracy: 0.0146 - val_loss: 83.6554 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 90.1799 - accuracy: 0.0170 - val_loss: 83.4192 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 87.0407 - accuracy: 0.0092 - val_loss: 83.1807 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 88.2243 - accuracy: 0.0121 - val_loss: 82.9411 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 89.6488 - accuracy: 0.0160 - val_loss: 82.7001 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 86.9630 - accuracy: 0.0124 - val_loss: 82.4597 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 88.6377 - accuracy: 0.0086 - val_loss: 82.2173 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 85.3936 - accuracy: 0.0189 - val_loss: 81.9720 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 3s 236ms/step - loss: 85.5736 - accuracy: 0.0231 - val_loss: 81.7245 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 3s 236ms/step - loss: 83.1182 - accuracy: 0.0132 - val_loss: 81.4755 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 3s 236ms/step - loss: 84.7903 - accuracy: 0.0132 - val_loss: 81.2248 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 3s 236ms/step - loss: 84.7654 - accuracy: 0.0155 - val_loss: 80.9742 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 83.8518 - accuracy: 0.0132 - val_loss: 80.7223 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 83.9428 - accuracy: 0.0157 - val_loss: 80.4680 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 3s 236ms/step - loss: 85.0851 - accuracy: 0.0191 - val_loss: 80.2133 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 82.2069 - accuracy: 0.0168 - val_loss: 79.9566 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 82.7976 - accuracy: 0.0158 - val_loss: 79.6996 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 83.1169 - accuracy: 0.0160 - val_loss: 79.4425 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 81.4172 - accuracy: 0.0199 - val_loss: 79.1834 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 3s 236ms/step - loss: 82.1214 - accuracy: 0.0155 - val_loss: 78.9226 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 3s 236ms/step - loss: 82.9686 - accuracy: 0.0163 - val_loss: 78.6617 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 3s 236ms/step - loss: 83.4117 - accuracy: 0.0131 - val_loss: 78.4019 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 80.4273 - accuracy: 0.0109 - val_loss: 78.1412 - val_accuracy: 0.0000e+00\n",
      "{'loss': [97.60704803466797, 97.30921936035156, 97.01187133789062, 96.71318054199219, 96.41423034667969, 96.11237335205078, 95.81134033203125, 95.5084457397461, 95.20448303222656, 94.89864349365234, 94.5899887084961, 94.28070068359375, 93.97090911865234, 93.65901184082031, 93.3449478149414, 93.03014373779297, 92.71415710449219, 92.3978500366211, 92.08001708984375, 91.76156616210938, 91.43937683105469, 91.11566162109375, 90.79023742675781, 90.46450805664062, 90.13741302490234, 89.80750274658203, 89.47579193115234, 89.14484405517578, 88.81322479248047, 88.4802474975586, 88.1446762084961, 87.80872344970703, 87.47100830078125, 87.13394165039062, 86.79505920410156, 86.4538345336914, 86.1095199584961, 85.76380157470703, 85.41636657714844, 85.06947326660156, 84.72189331054688, 84.37213134765625, 84.02127838134766, 83.6692123413086, 83.31703186035156, 82.9646987915039, 82.61054992675781, 82.25506591796875, 81.9001693725586, 81.54594421386719], 'accuracy': [0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.013749999925494194, 0.013749999925494194, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873], 'val_loss': [89.3819351196289, 89.19717407226562, 89.00878143310547, 88.81912231445312, 88.62548828125, 88.43138885498047, 88.23531341552734, 88.03665161132812, 87.83570098876953, 87.63175964355469, 87.42591857910156, 87.21902465820312, 87.01032257080078, 86.7980728149414, 86.58468627929688, 86.3691635131836, 86.15324401855469, 85.93545532226562, 85.7166519165039, 85.49443054199219, 85.27054595947266, 85.04484558105469, 84.818115234375, 84.58929443359375, 84.35777282714844, 84.1240463256836, 83.89022827148438, 83.65544891357422, 83.41918182373047, 83.18070983886719, 82.94111633300781, 82.70006561279297, 82.45974731445312, 82.21727752685547, 81.97200012207031, 81.72445678710938, 81.47547149658203, 81.22481536865234, 80.97418212890625, 80.72230529785156, 80.4680404663086, 80.21326446533203, 79.95661163330078, 79.69955444335938, 79.4425277709961, 79.18336486816406, 78.92256164550781, 78.66169738769531, 78.40189361572266, 78.14117431640625], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
      "Train loss: [97.60704803466797, 97.30921936035156, 97.01187133789062, 96.71318054199219, 96.41423034667969, 96.11237335205078, 95.81134033203125, 95.5084457397461, 95.20448303222656, 94.89864349365234, 94.5899887084961, 94.28070068359375, 93.97090911865234, 93.65901184082031, 93.3449478149414, 93.03014373779297, 92.71415710449219, 92.3978500366211, 92.08001708984375, 91.76156616210938, 91.43937683105469, 91.11566162109375, 90.79023742675781, 90.46450805664062, 90.13741302490234, 89.80750274658203, 89.47579193115234, 89.14484405517578, 88.81322479248047, 88.4802474975586, 88.1446762084961, 87.80872344970703, 87.47100830078125, 87.13394165039062, 86.79505920410156, 86.4538345336914, 86.1095199584961, 85.76380157470703, 85.41636657714844, 85.06947326660156, 84.72189331054688, 84.37213134765625, 84.02127838134766, 83.6692123413086, 83.31703186035156, 82.9646987915039, 82.61054992675781, 82.25506591796875, 81.9001693725586, 81.54594421386719]\n",
      "Train accuracy: [0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.013749999925494194, 0.013749999925494194, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873, 0.014999999664723873]\n",
      "Test loss: [89.3819351196289, 89.19717407226562, 89.00878143310547, 88.81912231445312, 88.62548828125, 88.43138885498047, 88.23531341552734, 88.03665161132812, 87.83570098876953, 87.63175964355469, 87.42591857910156, 87.21902465820312, 87.01032257080078, 86.7980728149414, 86.58468627929688, 86.3691635131836, 86.15324401855469, 85.93545532226562, 85.7166519165039, 85.49443054199219, 85.27054595947266, 85.04484558105469, 84.818115234375, 84.58929443359375, 84.35777282714844, 84.1240463256836, 83.89022827148438, 83.65544891357422, 83.41918182373047, 83.18070983886719, 82.94111633300781, 82.70006561279297, 82.45974731445312, 82.21727752685547, 81.97200012207031, 81.72445678710938, 81.47547149658203, 81.22481536865234, 80.97418212890625, 80.72230529785156, 80.4680404663086, 80.21326446533203, 79.95661163330078, 79.69955444335938, 79.4425277709961, 79.18336486816406, 78.92256164550781, 78.66169738769531, 78.40189361572266, 78.14117431640625]\n",
      "Test accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "historyX = modelX.fit(x_train, y_train,\n",
    "          batch_size=70,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_valid, y_valid))\n",
    "\n",
    "print(historyX.history)\n",
    "print('Train loss:', historyX.history['loss'])\n",
    "print('Train accuracy:', historyX.history['accuracy'])\n",
    "print('Test loss:', historyX.history['val_loss'])\n",
    "print('Test accuracy:', historyX.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA330lEQVR4nO3dd3gVZfbA8e8JCVVApEjvmAAJNSAWUAQFLLQFkSIIIqKgiOiuvbsWVHCRpUhTkCZFioBYcK0rBAi9B5CEFrq0kHJ+f7yX/SEmJIEkk9ycz/PkSe7cmTtnMB5e3nnnHFFVjDHG+K8ArwMwxhiTuSzRG2OMn7NEb4wxfs4SvTHG+DlL9MYY4+cs0RtjjJ+zRG+MMX7OEr3J1URkl4i09DoOYzKTJXpjjPFzluiNuYiI5BOR4SKy1/c1XETy+d4rISILReSYiBwRkR9FJMD33j9EJEZE/hCRLSLSwtsrMcYJ9DoAY7Kh54EmQD1AgXnAC8CLwBAgGijp27cJoCISDAwEGqnqXhGpDOTJ2rCNSZ6N6I35q+7Aa6p6UFVjgVeB+33vxQNlgEqqGq+qP6orGJUI5ANqiUiQqu5S1R2eRG/MRSzRG/NXZYHdF7ze7dsGMBTYDiwVkSgReQZAVbcDTwCvAAdFZLqIlMWYbMASvTF/tReodMHrir5tqOofqjpEVasCbYEnz8/Fq+pUVb3Zd6wC72Rt2MYkzxK9MRAkIvnPfwHTgBdEpKSIlABeAqYAiMjdIlJdRAQ4jpuySRKRYBG5zXfT9ixwBkjy5nKM+TNL9MbAIlxiPv+VH4gA1gLrgFXAG759awDfACeBX4F/q+oy3Pz828AhYD9QCng26y7BmJSJNR4xxhj/ZiN6Y4zxc5bojTHGz1miN8YYP2eJ3hhj/Fy2LIFQokQJrVy5stdhGGNMjrFy5cpDqloyufeyZaKvXLkyERERXodhjDE5hojsTuk9m7oxxhg/Z4neGGP8nCV6Y4zxc9lyjt4Yk/vEx8cTHR3N2bNnvQ4lW8ufPz/ly5cnKCgozcdYojfGZAvR0dEULlyYypUr42rGmYupKocPHyY6OpoqVaqk+TibujHGZAtnz56lePHiluQvQUQoXrx4uv/Vk6YRvYgMAh4CBPhYVYeLyAwg2LfL1cAxVa2XzLG7gD9w5VwTVDU8XREaY3INS/Kpu5w/o1QTvYiE4pJ8Y+AcsEREFqpqlwv2eR9XmzslzVX1ULqjS6fXX4dmzeCWWzL7TMYYk3OkZeqmJvCbqp5W1QTgP0DH82/6GjDci2vW4Jnjx2HUKLj1Vpfsly4Fq8BsjEmPq666yusQMkVaEv16oKmIFBeRgsCdQIUL3m8KHFDVbSkcr7j+mitFpF9KJxGRfiISISIRsbGxaY3/f4oWhR07YMQI2LkTWrWCJk1gwQJL+MaY3C3VRK+qm3C9L5cCS4BI3Hz7eV259Gj+ZlVtALQBBohIsxTOM1ZVw1U1vGTJZMs1pKpAARg4ELZvhzFj4OBBaNsW6teHWbMgyRq7GWPSQFV5+umnCQ0NJSwsjBkzZgCwb98+mjVrRr169QgNDeXHH38kMTGRBx544H/7Dhs2zOPo/ypNN2NVdTwwHkBE/glE+34OxE3jNLzEsTG+7wdFZC5urv+HKwv70vLlg379oHdvmDYN3nwTOneGWrXgueegSxcItIWlxmRbTzwBkZEZ+5n16sHw4Wnbd86cOURGRrJmzRoOHTpEo0aNaNasGVOnTqVVq1Y8//zzJCYmcvr0aSIjI4mJiWH9+vUAHDt2LGMDzwBpWl4pIqV83yviEvtU31stgc2qGp3CcYVEpPD5n4E7cFNBWSIoCHr2hI0bXcIPCIAePaBmTZgwAeLjsyoSY0xO8tNPP9G1a1fy5MnDtddeyy233MKKFSto1KgREydO5JVXXmHdunUULlyYqlWrEhUVxWOPPcaSJUsoUqSI1+H/RVrHtbNFpDgQDwxQ1WO+7fdx0bSNiJQFxqnqncC1wFzfcqBAYKqqLsmIwNMjTx647z64916YNw/eeAMefBBefRWeeQb69HH/CjDGZA9pHXlntWbNmvHDDz/w5Zdf8sADD/Dkk0/Ss2dP1qxZw1dffcXo0aOZOXMmEyZM8DrUP1PVbPfVsGFDzUxJSaqLFqnecIMqqJYtqzp8uOqpU5l6WmPMJWzcuNHrELRQoUKqqjp79my94447NCEhQQ8ePKgVK1bUffv26a5duzQhIUFVVUeMGKGDBg3S2NhYPX78uKqqrlu3TuvWrZvpcSb3ZwVEaAo5NVc+GSsCbdrAzz/DN99AjRpuTrBKFRg6FE6e9DpCY4yXOnToQJ06dahbty633XYb7777LqVLl+b777+nbt261K9fnxkzZjBo0CBiYmK49dZbqVevHj169OCtt97yOvy/EM2Gaw/Dw8M1qxuP/Pije+Dq66+heHEYPNit4ClaNEvDMCbX2rRpEzVr1vQ6jBwhuT8rEVmpKVQeyJUj+uQ0beoesvr1V7f+/oUXoHJlePllOHLE6+iMMebyWaK/SJMmsHAhRES4p2xfe80l/Oeeg8t4jssYYzxniT4FDRvC3LmwZo2bz3/7bZfwn3oK9u/3OjpjjEk7S/SpqFMHZsyADRugY0cYNszdtH3iCdi71+vojDEmdZbo06hmTZg8GbZsga5d4aOPoGpVd8M2OtnHxYwxJnuwRJ9O1au7p2q3boX773c1dapVg0cegd27vY7OGGP+yhL9ZapaFT7+2BVQ69MHxo93fwk89BBERXkdnTHG/D9L9FeoUiVXB3/HDujf303vXHedK6i2LaXCzcaYHO9Stet37dpFaGhoFkZzaZboM0iFCq4WflSUm7efPh1CQtz0zubNXkdnjMnNrFhvBitb1hVkeuYZeO89N9r/7DNXVO2FF1ypZGPMpT2x5Aki90dm6GfWK12P4a2Hp/j+M888Q4UKFRgwYAAAr7zyCoGBgSxbtoyjR48SHx/PG2+8Qbt27dJ13rNnz/LII48QERFBYGAgH3zwAc2bN2fDhg307t2bc+fOkZSUxOzZsylbtiz33nsv0dHRJCYm8uKLL9KlS5fUT5IKG9FnktKlXaLfuROefhrmz4fQUFcLf32WFWo2xqRVly5dmDlz5v9ez5w5k169ejF37lxWrVrFsmXLGDJkCOktGzNy5EhEhHXr1jFt2jR69erF2bNnGT16NIMGDSIyMpKIiAjKly/PkiVLKFu2LGvWrGH9+vW0bt06Q67NRvSZrFQpeOcdl+w/+MBN78ycCZ06wUsvQViY1xEak/1cauSdWerXr8/BgwfZu3cvsbGxFCtWjNKlSzN48GB++OEHAgICiImJ4cCBA5QuXTrNn/vTTz/x2GOPARASEkKlSpXYunUrN9xwA2+++SbR0dF07NiRGjVqEBYWxpAhQ/jHP/7B3XffTdOmTTPk2mxEn0VKlIB//hN27YLnn4evvnIPY/3tb+7pW2OM9zp37sysWbOYMWMGXbp04bPPPiM2NpaVK1cSGRnJtddey9mzZzPkXN26dWP+/PkUKFCAO++8k++++47rrruOVatWERYWxgsvvMBrr72WIeeyRJ/Fihd3jU9273Yj+m++cS3OOnSA1au9js6Y3K1Lly5Mnz6dWbNm0blzZ44fP06pUqUICgpi2bJl7L6Mh2WaNm3KZ599BsDWrVv5/fffCQ4OJioqiqpVq/L444/Trl071q5dy969eylYsCA9evTg6aefZtWqVRlyXZboPVKsmOtwtWuXq5C5bBk0aADt2kEG/bc1xqRT7dq1+eOPPyhXrhxlypShe/fuREREEBYWxqeffkpISEi6P/PRRx8lKSmJsLAwunTpwqRJk8iXLx8zZ84kNDSUevXqsX79enr27Mm6deto3Lgx9erV49VXX+WFF17IkOtKUz16ERkEPAQI8LGqDheRV3zbztd0fE5VFyVzbGvgQyAPrsXg26mdz4t69F47dgz+9S9XS+fYMWjb1v0F0KCB15EZkzWsHn3aZXg9ehEJxSX0xkBd4G4Rqe57e5iq1vN9JZfk8wAjgTZALaCriNgCw2RcfbWbytm1y5VG/uEHV0HTRvjGmCuVlqmbmsBvqnpaVROA/wAd0/j5jYHtqhqlqueA6UD6FqHmMkWLwosvWsI3JidYt24d9erV+9PX9ddf73VYf5GWRL8eaCoixUWkIHAnUMH33kARWSsiE0SkWDLHlgP2XPA62rftL0Skn4hEiEhErHX4uGTCt5u2xl9lx9amlxIWFkZkZOSfvn777bdMPefl/BmlmuhVdRPwDrAUWAJEAonAKKAaUA/YB7yf7rP/+TxjVTVcVcNLlix5JR/lV5JL+A0auNr4a9d6HZ0xGSd//vwcPnw4xyX7rKSqHD58mPz586fruHQ3BxeRfwLRqvrvC7ZVBhaqauhF+94AvKKqrXyvn/UFe8k26bnxZmxaHTvmSiwMGwYnTrh1+C+/bA9emZwvPj6e6OjoDFun7q/y589P+fLlCQoK+tP2S92MTeuqm1KqelBEKuJG9k2AAqq6z/f+YOB6Vb3vouMCga1ACyAGWAF0U9UNlzqfJfrUHT3qkv3w4fDHH9C5s0v4tWt7HZkxxgtXtOrGZ7aIbAQWAANU9RjwroisE5G1QHNgsO9kZUVkEYDv5u1A4CtgEzAztSRv0qZYMTeVc/5J28WL3ai+a1erlmmM+bN0T91kBRvRp9+hQ/D++66WzpkzLuG/9JKrjW+M8X8ZMaI32VyJEvDWW65a5pAhMHeu63Pbq5frgmWMyb0s0fuZkiXh3XddA5QnnnCVMkNCXLtDa3FoTO5kid5PXXutm8o53/Fq6lQIDoZ+/ayJuTG5jSV6P1emjFuZc76n7SefQI0a8MgjEB3tdXTGmKxgiT6XKFfO3ajdvh0efBDGj4dq1eDxx2HfPq+jM8ZkJkv0uUyFCq6P7bZt0LMn/PvfULWqu4F78KDX0RljMoMl+lyqUiX4+GPYssX1sR0+HKpUcU3NDx/2OjpjTEayRJ/LVasGkybBxo2uYNq777qE//LLrtyCMSbns0RvALciZ+pUWLcO7rjDPXVbpYrrc3vypNfRGWOuhCV68ye1a8OsWa72/c03u/IKVaq4pZqnT3sdnTHmcliiN8mqXx8WLID//tf9/NRTUL06fPQRxMV5HZ0xJj0s0ZtLuv56WLrU1cGvUQMee8x9HzcO4uO9js4YkxaW6E2aNG0K338PX38NZcvCQw+50gqTJ0NiotfRGWMuxRK9STMRaNkSfv3VTesUKeLW4oeGwuefQ1KS1xEaY5Jjid6kmwjcfTesXOkSfEAA3Huv62m7cCFkw8rXxuRqlujNZQsIgE6dXO/ayZNdp6t77oEbboBvvrGEb0x2kaZELyKDRGS9iGwQkSd824aKyGYRWSsic0Xk6hSO3eXrRBUpItZNxA/lyQM9esCmTe5p27174fbboXlz+Plnr6MzxqSa6EUkFHgIaAzUBe4WkerA10CoqtbB9YV99hIf01xV66XU/cT4h6Ag6NvX1dH5179cS8Obb4Y2bdw0jzHGG2kZ0dcEflPV074esP8BOqrqUt9rgP8C5TMrSJOz5MvnlmFGRcE778Dy5RAeDh07wvr1XkdnTO6TlkS/HmgqIsVFpCBwJ1Dhon36AItTOF6BpSKyUkT6pXQSEeknIhEiEhEbG5uW2E02V7Ag/P3vrr3hq6/Ct99CnTrQrZsb9RtjskaqiV5VNwHvAEuBJUAk8L+V0yLyPJAAfJbCR9ysqg2ANsAAEWmWwnnGqmq4qoaXLFkyXRdhsrciRVyj8qgo+Mc/YN4818+2b1/4/XevozPG/6XpZqyqjlfVhqraDDiKm5NHRB4A7ga6qya/xkJVY3zfDwJzcXP9JhcqXtw1MN+xAwYMcCt1atRwzU/27/c6OmP8V1pX3ZTyfa8IdASmikhr4O9AW1VNttyViBQSkcLnfwbuwE0FmVysdGn48MM/Nz+pVs3Vwj9yxOvojPE/aV1HP1tENgILgAGqegz4CCgMfO1bOjkaQETKisgi33HXAj+JyBpgOfClqi7J0CswOVbFim455qZN0L79/9fCf/11tybfGJMxJIUZF0+Fh4drRIQtuc9t1q+HF1+EL76AEiXcCP/RR6FAAa8jMyb7E5GVKS1htydjTbYRGgpz58Jvv/25NPKoUXDunNfRGZNzWaI32U7jxq408rJlULmyG9XXrAlTplilTGMuhyV6k23deiv89BN8+SUULgz33w/16sH8+VZHx5j0sERvsjURuPNO19pw+nTX3apdO7jxRjfiN8akzhK9yRECAqBLF9iwAcaOhT174LbbXCNzq6NjzKVZojc5SlCQ6261bRu8954b6YeHu3r4W7Z4HZ0x2ZMlepMjFSgAQ4a4sgovvQSLFkHt2u4vgehor6MzJnuxRG9ytCJFXMG0qCgYOBA+/dQtyXzqKTh82OvojMkeLNEbv1CqFAwfDlu3QteuMGwYVK0Kb7wBJ096HZ0x3rJEb/xKpUowcaJrb3jbbe5J2+rVYeRIe+jK5F6W6I1fql3bPWX7yy8QHOymdUJC4LPPICnJ6+iMyVqW6I1fu+EG+P57WLwYihZ1vW3r13c3b+2hK5NbWKI3fk8EWrd26+2nToVTp+Cuu+CWW9yI3xh/Z4ne5BoBAe5G7caNrgb+tm1w003uSVvrZWv8mSV6k+vkzQuPPALbt8Obb7qpnTp1oFcv2L3b6+iMyXiW6E2uVagQPPecW4M/ZAjMmAHXXQeDB8OhQ15HZ0zGSWsrwUEisl5ENojIE75t14jI1yKyzfe9WArH9vLts01EemVg7MZkiOLFYehQN5XTowf8619uDf7rr9safOMfUk30IhIKPIRr6l0XuFtEqgPPAN+qag3gW9/ri4+9BngZuN53/Msp/YVgjNcqVIDx4918fcuWrrRC9epuPj8+3uvojLl8aRnR1wR+U9XTqpoA/AfXILwd8Ilvn0+A9skc2wr4WlWPqOpR4Gug9RVHbUwmqlkT5syBX391a+8HDIBatWDmTFuDb3KmtCT69UBTESkuIgWBO4EKwLWqus+3z35cI/CLlQP2XPA62rftL0Skn4hEiEhEbGxsmi/AmMzSpImref/ll66IWpcucP318N13XkdmTPqkmuhVdRPwDrAUWAJEAokX7aPAFT1+oqpjVTVcVcNLlix5JR9lTIY53/hk9Wr45BM4eBBatIBWrdw2Y3KCNN2MVdXxqtpQVZsBR4GtwAERKQPg+34wmUNjcKP/88r7thmTo+TJAz17upr3778PERHQoIG7ebtrl9fRGXNpaV11U8r3vSJufn4qMB84v4qmFzAvmUO/Au4QkWK+m7B3+LYZkyPlzw9PPgk7dsAzz8Ds2a6WzpNPWllkk32ldR39bBHZCCwABqjqMeBt4HYR2Qa09L1GRMJFZByAqh4BXgdW+L5e820zJke7+mp4663/X5L54YdQrRq8/TacOeN1dMb8mWg2rOwUHh6uERER6T7uRNwJiuQrkgkRGXNp69fDs8/CwoVQrpxrhtKrFwQGeh2ZyS1EZKWqhif3nt88GZukSQR/FEyDMQ14ednLROyNIEltLZzJGqGhsGCBK6dQvjz07Qt168L8+VYl03jPbxL9ucRzDG4ymIJBBXnjxzdo9HEjKgyrwMMLHmbh1oWcibd/T5vMd8stbv39rFmQkOAKpjVr5rYZ4xW/mro5L/ZULIu2LWLB1gV8teMrTp47ScGggtxR7Q7aBbfj7uvupkTBEhkYsTF/FR8PEybAK6/A/v3QoQP885/uISxjMtqlpm78MtFfKC4hju93fc/8LfOZv3U+0SeiCZAAbqpwE22D29IuuB01itfIkHMZk5xTp1wP23ffhdOn4cEHXfIvU8bryIw/ydWJ/kKqyqp9q5i/ZT7ztsxjzYE1ANQqWYt2we1oH9Ke8LLhBIjfzGiZbCQ21hVKGz0agoJclcy//x2K2PoBkwEs0adg17Fd/0v6/9n1HxI1kTJXlaFdcDvahbTjtiq3kTdP3kyPw+QuO3bA88+7ssglSrgG5v37uzr5xlwuS/RpcOTMERZtW8QXm79gyfYlnIo/RZF8Rbirxl10COlAmxptuCrvVVkak/FvERHwj3+42jlVq7omKPfe6zphGZNelujT6WzCWb6N+pa5m+cyf8t8Yk/Hki9PPlpWbUmHkA60DW5LyUJWj8dcOVVYssQl/HXrIDzczeU3b+51ZCansUR/BRKTEvl5z8/M3TSXuZvnsvv4bgIkgKYVm9IhpAMdanagYtGKXodpcrjERJgyxU3j7NkDbdrAO+9AWJjXkZmcwhJ9BlFVIvdHMnfzXOZsmsOG2A0ANCzTkA4hHehYsyM1S9b0OEqTk505Ax995JZhHj8ODzwAr73mHsIy5lIs0WeSbYe3/S/p/xbzGwAhJULoGNKRv9X6G/VL10dEPI7S5ERHjrhkP2KEq5x5foVO0aJeR2ayK0v0WSDmRAxfbP6COZvn/G8FT6Wilf430r+xwo3kCcjjdZgmh9m1y63QmTrVrdB5+WXo189W6Ji/skSfxQ6dPsSCLQuYu3kuS3csJS4xjtJXlaZ9cHs61erELZVvITDAql2ZtFu5Ep5+2nW8ql7dVc78299cYxRjwBK9p/6I+4NF2xYxa9MsFm1bxOn401xT4BraBbejU61OtKza0tbqmzRRhcWL3RTOhg1www0wdCjcdJPXkZnswBJ9NnE6/jRfbf+K2Ztms2DrAk7EnaBovqK0DW5Lp1qduKPaHeQPzO91mCabS0yESZPcCp19+1wNnbffhuuu8zoy4yVL9NlQXEIc30R9w6xNs/hi8xccO3uMwnkLc0/wPXSq2YnW1VtTIKiA12GabOx8DZ133nGrdR5+2M3hlyrldWTGC5bos7lziedYtnMZszbOYu7muRw+c5hCQYW4J/geOtfqTJvqbSzpmxQdOOAanYwdCwUKuBaHgwdDwYJeR2ay0hUnehEZDPQFFFgH9Aa+Bgr7dikFLFfV9skcm+g7BuB3VW2b2vlyW6K/UEJSAst2LuPzjZ8zZ9McS/omzTZvdl2uvvjCdbl64w24/363PNP4vytK9CJSDvgJqKWqZ0RkJrBIVSddsM9sYJ6qfprM8SdVNV1FYnJzor9Qckn/qrxX0Ta4LffWupdW1VvZnL75ix9/hCFDYMUKqFMH3nsPbr/d66hMZsuIVoKBQAERCQQKAnsv+PAiwG3AF1cYp7lIYEAgt1e7nbH3jGX/U/tZ2mMp99W+jyXbl9B+RntKDS3F/XPvZ+HWhcQlxHkdrskmmjaF//4Xpk2DEyfgjjugdWtYu9bryIxX0jp1Mwh4EzgDLFXV7he81xNoq6qdUjg2AYgEEoC3VfWLFPbrB/QDqFixYsPdu3en60Jyk/jEeL7b+R0zN8xk7ua5HD17lKL5itI+pD1danehZdWWBOUJ8jpMkw3ExcHIkW4a59gxV1Lh9dfd1I7xL1c6dVMMmA10AY4BnwOzVHWK7/3FwDhVnZ3C8eVUNUZEqgLfAS1UdcelzmlTN2l3LvEc30R9w8wNM/li8xccjzvONQWuoUNIB7rU7kLzKs3t4SzDkSOuDPJHH7k5+yefdBUzCxdO/ViTM1xpou8MtFbVB32vewJNVPVRESkBbAHKqerZNAQyCVioqrMutZ8l+ssTlxDH0h1LmblxJvM2z+OPc39QomAJOtXsRJfQLjSt2NTKMORyO3fCc8/B9OlQsqRrafjQQ67jlcnZrnSO/negiYgUFFehqwWwyfdeJ1ziTjbJi0gxEcnn+7kEcBOwMb0XYNImX2A+7gm+h8kdJnPw6YPMuXcOLau25NO1n9L8k+ZUGFaBxxc/zi97fiFJk7wO13igShU3d798OdSsCQMGuFLI8+e7J2+Nf0rrHP2ruKmbBGA10FdV40Tke9y8+5IL9g0H+qtqXxG5ERgDJOH+UhmuquNTO5+N6DPWqXOn+HLbl0xfP51F2xYRlxhHhSIV6FK7C13DulqVzVxKFRYscCUVtmyBW25xK3TCkx0TmuzOHpgy/3Mi7gTzNs9j+obpLN2xlISkBK4rfh1dQ7vSNbQrwSWCvQ7RZLH4eBg3zj1VGxsL3bq5EsmVKnkdmUkPS/QmWYdPH2b2ptlMWz+N/+z6D4pSv3R9uoZ25b7Q+6hQtILXIZosdOKEa2P4/vtutD9okJvPtxr4OYMlepOqmBMxfL7xc6atn8bymOUA3FzxZrqFdqNTrU7WIzcXiY6GF16ATz+F4sXdDdt+/eyGbXZnid6ky/Yj25m+fjpT101l06FN5JE83F7tdrqFdqN9SHsK57M1ebnB6tXuCdtlyyA42I3277nHauBnV5bozWVRVdYeWMu09dOYtn4avx//nQKBBWgb3JZuYd1oXb211dL3c6qwcKFrerJlC9x6q5vaadDA68jMxSzRmyuWpEn8uudXpq6byowNMzh85jDF8hejc63OdAvrRtNKTQmQtFbUMDlNfDx8/LG7YXv4MPTs6R7Asidssw9L9CZDxSfG83XU10xdN5UvNn/BqfhTlC9Snq6hXekW1o2619a15Zp+6vhxtyJn+HAIDHQj/aefhkKFvI7MWKI3mebUuVPM3zKfqeunsmT7EhKSEqhZoibdw7rTNawrVYtV9TpEkwl27nR172fOhLJlXfK//34IsH/UecYSvckSh08f5vONnzN13VR+/P1HAG4ofwPdw7pzb+17beWOH/rlF9fkZPlyN2//wQfuwSuT9SzRmyy3+9hupq+fzpR1U1h/cD2BAYHcUe0Ouod1p11wOwrltX/r+4ukJJgxwxVJ27PH9bB9912oXt3ryHIXS/TGU2sPrOWztZ8xdf1Uok9EUyioEB1qdqBHWA9aVG1h1TX9xJkzroftW2+58siPPebW4xcr5nVkuYMlepMtJGkSP+7+kSlrpzBr0yyOnT3GtYWu5b7Q++ge1p3wsuF2E9cP7N/vEvyECXDNNe6Bq4cftgeuMpslepPtxCXEsWjbIqasm8LCrQs5l3iO64pfR4+wHvSo04Mqxap4HaK5QpGRru79smUQEuLm79u08Toq/2WJ3mRrR88cZfam2UxeO5kfdv8AuPIL99e5n861OlOsgP3bP6dSdSWQn3oKtm+HVq3cA1e1a3sdmf+xRG9yjN3HdvPZus+YvHYymw9tJm+evNxz3T30rNvTnsTNwc6dcy0NX30VTp50UzmvvgolSngdmf+wRG9yHFVl5b6VTF4zmWnrpxF7OpYSBUvQNbQr99e53+bzc6hDh9yc/ejRcNVV8NJLMHAg5LW/v6+YJXqTo8UnxrN0x1I+Xfsp8zbPIy4xjpASIfSs05MedXpYOeUcaONGVzBtyRK3DHPoUGjXzgqmXYkrbSWIiAwWkQ0isl5EpolIfhGZJCI7RSTS91UvhWN7icg231evK7gOk0sF5QniruvuYkanGex/aj9j7x5LyYIlee6756g0vBItPm3Bp2s+5eS5k16HatKoVi1YvNh95c3r1t63aOFu4JqMl5bm4OWAn4BaqnpGRGYCi4BbSaXRt4hcA0QA4YACK4GGqnr0Uue0Eb1Ji6ijUUxZO4VP1nxC1NEoCgYV5G81/0avur24tfKt1gg9h0hIgLFj3TTOkSPQpw+88QaULu11ZDnLFY/ogUCggIgEAgWBvWk8rhXwtaoe8SX3r4HWaTzWmEuqWqwqL93yEtsf286PvX+ke1h35m2ZR8vJLan8YWWe/eZZNh/a7HWYJhWBgfDoo25VzpNPuoYnNWq4B6/OnvU6Ov+QaqJX1RjgPeB3YB9wXFWX+t5+U0TWisgwEcmXzOHlgD0XvI72bfsLEeknIhEiEhEbG5uuizC5m4hwc8WbGXvPWPYP2c+0v00jrFQY7/7yLjVH1uT6cdfz7xX/5siZI16Hai7h6qtdc/KNG+H2210bw5AQV14hG95KzFFSTfQiUgxoB1QBygKFRKQH8CwQAjQCrgH+cSWBqOpYVQ1X1fCSJa34lbk8BYIKcF/ofSzqvojowdEMvX0op+NPM2DRAMq8X4bOn3fmy61fkpCU4HWoJgXVq8OcOfDddy7533cfNG0KK1Z4HVnOlZapm5bATlWNVdV4YA5wo6ruUycOmAg0TubYGODCJRHlfduMyXRlCpfhqRufYm3/tazqt4pHwh/h+13fc/e0uyn/QXmeWvoU6w6s8zpMk4LmzWHlShg3zk3rNG7sSiHHWAZJt7TcjL0emIAbuZ8BJuFusM5S1X3iFjMPA86q6jMXHXsN7gbs+cZjq3A3Yy/5b2i7GWsyy7nEcyzetphJayaxcOtCEpISaFCmAQ/UfYBuYd0oXrC41yGaZPzxh6t5P2wY5MnjKmU+9RQULOh1ZNnHFa+jF5FXgS5AArAa6AssBkoCAkQC/VX1pIiE+37u6zu2D/Cc76PeVNWJqZ3PEr3JCrGnYpm2fhqTIiexev9qggKCaBvclt71etOqeiurqpkN7dwJf/87zJoFFSrAO++4qR1bf28PTBmTqjX71zApchJT1k3h0OlDlLmqDPfXuZ/e9XsTUiLE6/DMRX74AZ54AlavhhtucK0NGyc3eZyLWKI3Jo3OJZ7jy61fMjFyIou2LSJRE2lSvgl96vWhS2gXiuQr4nWIxicxET75xK3OOXDANSz/5z9zb8NyS/TGXIYDJw8wee1kJkZOZGPsRgoEFqBz7c70qdeHZpWaWa2dbOL8/P0HH7g1+c8+68orFCjgdWRZyxK9MVdAVVkes5yJkROZtn4aJ+JOUK1YNR6o9wAP1HuA8kXKex2iAaKi4Omn3dLMSpVcO8POnXPP/L0lemMyyOn408zZNIfxq8fz/a7vEYQ7qt1Bn/p9aBfcjnyByT03aLLS99+7+fs1a+Dmm938fcOGHgeVBSzRG5MJoo5GMSlyEpMiJ7HnxB6uKXAN3cO606d+H+qVrud1eLlaYqJrZfj88640cu/e8Oab/l0/xxK9MZkoMSmR73Z+x4TICczdNJe4xDjql65Pn/p96BbWjWsKXON1iLnW8ePw+uvwr39B/vyul+2gQZDPD//hZYnemCxy9MxRpq6byoTICazat4q8efLSIaQDD9Z/kBZVWxAgaa0jaDLStm3uBu2CBVCtmqup42/17y3RG+OByP2RTFg9gSlrp3D07FEqFq3IA3UfoHf93lS+urLX4eVKS5fC4MGucNptt7n5+7Awr6PKGJbojfHQ2YSzzN8yn/Grx/P1jq8BaFG1BQ/Wf5D2Ie3JH5jf4whzl/h418rw5Zfd1E7//v7Rv9YSvTHZxO5ju5kUOYmJkRPZfXw3xfIXo0edHvRt0Jc619bxOrxc5fBh17921CgoXNgl+0cegaAgryO7PJbojclmkjSJb6O+Zfzq8czdPJdziedoVLYRD9Z/kK5hXe0J3Cy0YYObzvn6a6hZ0z141ToHtkfKiA5TxpgMFCAB3F7tdqZ3ms7eJ/fyYesPOZtwlv5f9qfM+2XoPa83P//+M9lxIOZvateGr76CefPctE6bNnD33bB1q9eRZRwb0RuTTagqEXsjGLdqHFPXT+XkuZOElAihb/2+9Kzbk5KFrCFPZouLgxEj3JLM06fh8cfhxRddA5TszqZujMlhTp47yecbPmfc6nH8sucXggKCaB/Snr4N+tKyaktbppnJDhxwa+7Hj4fixV2z8r59XS387MoSvTE52MbYjYxbNY5P13zK4TOHqVS0En3q96FP/T5WZyeTrV7tyin88APUrQsffgi33OJ1VMmzRG+MH4hLiGPelnl8vOpjvon6hgAJoHX11jzU4CHuqnEXQXly6HKRbE7VNTp5+mnYvdsVShs61BVOy04yosPUYFxXKQXWAb2B8UA4EA8sBx729ZS9+NhE3zEAv6tq29TOZ4nemEuLOhrF+FXjmRg5kX0n91H6qtL0rtebB+s/SLVrqnkdnl86c8Y9UfvWWy75P/20a2lYqJDXkTlXlOhFpBzwE1BLVc+IyExgEXAQ104QYCrwg6qOSub4k6p6VXoCtkRvTNokJCWwaNsiPl71MYu2LSJJk2hRpQV9G/SlQ0gHq6aZCfbscQl+2jQoX96VQ84O7QwzYnllIFBARAKBgsBeVV2kPrgRvU0WGpPFAgMCaRvclgVdF7D7id28dutrbD+yna6zu1L2g7IMXjKYjbEbvQ7Tr1SoAFOnwo8/QqlS0K0bNG0KK1d6HVnKUk30qhoDvAf8DuwDjqvq0vPvi0gQcD+wJIWPyC8iESLyXxFpf+UhG2OSU75IeV685UWiBkXxVY+vaFGlBSNXjKT2v2tz04SbmBQ5idPxp70O02/cfDMsXw7jxrmiaY0auZU5Bw96HdlfpWXqphgwG+gCHAM+B2ap6hTf+x8Dp1T1iRSOL6eqMSJSFfgOaKGqO5LZrx/QD6BixYoNd+/efbnXZIzxOXjqIJPXTObjVR+z5fAWiuYrSvew7jzU8CGrmZ+Bjh+H115z5ZALFnR1dAYOhLx5sy6GK52j7wy0VtUHfa97Ak1U9VEReRmoD3RU1aQ0BDIJWKiqsy61n83RG5OxVJWffv+JsavG8vmGz4lLjKNR2UY81OAhuoZ15aq86bqNZlKwZYsrp7B4MQQHw7Bh7knbrHClc/S/A01EpKC4bsgtgE0i0hdoBXRNKcmLSDERyef7uQRwE2AThsZkMRGhaaWmTO4wmb1DXMmF0/Gn6bewH2XeL0P/hf1ZvW+112HmeMHBsGgRLFwISUlw553Zo5xCWpdXvoqbukkAVuOWWp4CdgN/+Habo6qviUg40F9V+4rIjcAYIAn3l8pwVR2f2vlsRG9M5lNVfo3+lbErxzJjwwzOJpwlvGw4Dzd8mPtC77NR/hU6d85N5bz2Gpw96zpbvfACFC2aOeezB6aMMZd09MxRpqydwpiVY9gQu4HCeQvTo04PHm74MHVL1/U6vBxt/37Xu3biRChZ0q3Df+ABCMjgKhaW6I0xaXJ+lD9m5RhmbpjJ2YSzNCnfhIcbPsy9te+lYFBBr0PMsSIiXJG0X3+Fhg1dOYWbbsq4z7cyxcaYNBERbqxwI5+0/4SYJ2MY1moYx84eo/e83pT7oByDFg+ydfmXKTwcfv4Zpkxxo/ybb4bu3SE6OvPPbSN6Y8wlqSo/7P6BMSvHMGvjLOKT4mlWqRn9G/anY82O9vTtZTh5Et55x9XMyZMHnnkGnnoKChS4/M+0qRtjTIaIPRXLxMiJjFk5hqijUZQsWJI+9fvQr2E/qhar6nV4Oc7Ona5mzuzZrkja0KHQqdPllVOwRG+MyVBJmsQ3Ud8wOmI087fMJ0mTaFW9Ff0b9ueu6+4iMCDQ6xBzlGXL3KqcI0fcUsyCl3ErxBK9MSbTxJyIYfzq8YxdOZaYP2IoX6Q8/Rr0o2+DvpQpXMbr8HKMhAQ3wq9R4/KOt0RvjMl0CUkJLNy6kFERo1i6YymBAYG0D2nPI+GP0Lxyc8Tr8o5+zhK9MSZLbT+ynTERY5gQOYEjZ44QXDyY/uH96VW3F8UKFPM6PL9kid4Y44mzCWf5fMPnjIoYxa/Rv5I/MD/3hd7HI+GP0KhsIxvlZyBL9MYYz63Zv4ZREaOYsnYKp+JP0aBMAx4Jf4SuoV0plDebtGnKwSzRG2OyjRNxJ/hs7WeMihjFuoPrKJqvKL3q9qJ/eH9qlqzpdXg5liV6Y0y2o6r8vOdnRkWM4vMNnxOfFE/zys15JPwR2oe0t2bn6WSJ3hiTrR08dZAJqycwOmI0u4/vpvRVpenXoB/9GvajXJFyXoeXI1iiN8bkCIlJiSzevphREaNYvG0xARJA+5D2PNroUVuimQpL9MaYHGfHkR2MWTmG8avHc+TMEUJKhPBo+KP0rNuTovkzqah7DmaJ3hiTY52JP8PMDTMZuWIkK/auoFBQIXrU6cGARgMIuzbM6/CyDUv0xhi/ELE3gpErRjJ9/XTOJpylacWmPNroUTrW7EjePFnYiTsbuuJ69CIyWEQ2iMh6EZkmIvlFpIqI/CYi20Vkhogk+6csIs/69tkiIq2u5EKMMblbeNlwJrabSPTgaIbePpSYP2LoOrsrlYZX4qVlLxFzIsbrELOlVEf0IlIO+AmopapnRGQmsAi4E9cndrqIjAbWqOqoi46tBUwDGgNlgW+A61Q18VLntBG9MSYtkjSJr7Z/xcgVI1m0bREBEkCHmh0Y2GggzSo1y1U3bzOiw1QgUEBEAoGCwD7gNmCW7/1PgPbJHNcOmK6qcaq6E9iOS/rGGHPFAiSANjXasLDbQrY/vp3BTQbzbdS33PrJrYSNCmPUilGcPHfS6zA9l2qiV9UY4D3gd1yCPw6sBI6paoJvt2ggucWu5YA9F7xOaT9EpJ+IRIhIRGxsbNqvwBhjgKrFqjL0jqHEPBnDhLYTyBeYj0cXPUq5D8rx+OLH2XJoi9cheibVRC8ixXAj8yq46ZdCQOuMDkRVx6pquKqGlyxZMqM/3hiTSxQIKkDv+r2JeCiCX/r8wj3X3cPoiNGEjAzh9sm3M2/zPBKTLjl77HfSMnXTEtipqrGqGg/MAW4CrvZN5QCUB5K7CxIDVLjgdUr7GWNMhhIRbqhwA1M6TmHP4D280fwNNh/aTPsZ7an6r6q8/dPbxJ7KHbMHaUn0vwNNRKSguDsbLYCNwDKgk2+fXsC8ZI6dD9wnIvlEpApQA1h+5WEbY0zaXXvVtTzf7Hl2DtrJ7HtnU61YNZ799lkqDKtAry96sSJmhdchZqo0raMXkVeBLkACsBroi5trnw5c49vWQ1XjRKQtEK6qL/mOfR7o4zv2CVVdnNr5bNWNMSazbYzdyMjlI/l07aecPHeSxuUaM7DRQDrX7kz+wPxeh5du9sCUMcak4ETcCT5d8ykjV4xk86HNlChYgn4N+tE/vD8VilZI/QOyCUv0xhiTClXlu53f8dGKj5i/ZT6C0D6kPQMbD+SWSrdk+zX5luiNMSYddh3bxeiI0Xy86mOOnDlCaKlQBjYaSI86PbJtN6yMeGDKGGNyjcpXV+btlm8TPTiaCW0nEBQQRP8v+1N+WHmGfDWEqKNRXoeYLjaiN8aYVKgqv+z5hRHLRzB702wSkxK567q7eKzxY9xe9fZsMa1jUzfGGJNBYk7EMGblGMasHMPBUwcJKRHCwEYD6Vm3J4XzFfYsLkv0xhiTweIS4pi5YSYjlo9gxd4VFMlXhAfqPsDAxgOpUbxGlsdjid4YYzLRb9G/MWL5CGZumEl8UjxtqrfhscaP0ap6KwIka26FWqI3xpgssP/kfsauHMuoiFHsP7mf6tdUZ0CjAfSu1zvT2x9aojfGmCx0LvEcczbNYcTyEfyy5xcKBRWiZ92eDGw8kFola2XKOS3RG2OMR1btW8WI5SOYtm4acYlx3FblNh5r/Bj3XHcPeQLyZNh5LNEbY4zHDp0+xLhV4/j3in+z58QeKhWtxKONHuXB+g9SvGDxK/58S/TGGJNNJCQlMH/LfEYsH8H3u74nf2B+uod157HGj1G3dN3L/lxL9MYYkw2tO7COj5Z/xOS1kzmTcIZmlZqxtMdS8gXmS/dnWQkEY4zJhsKuDWPMPWOIeTKG925/j+DiwZeV5FMTmPouxhhjMlOxAsUYcuOQTPt8G9EbY4yfS3VELyLBwIwLNlUFXgJuAIJ9264GjqlqvWSO3wX8ASQCCSnNIRljjMkcqSZ6Vd0C1AMQkTy45t5zVXX4+X1E5H3g+CU+prmqHrqiSI0xxlyW9M7RtwB2qOru8xt8DcPvBW7LyMCMMcZkjPTO0d8HTLtoW1PggKpuS+EYBZaKyEoR6ZfSB4tIPxGJEJGI2NjYdIZljDEmJWlO9CKSF2gLfH7RW135a/K/0M2q2gBoAwwQkWbJ7aSqY1U1XFXDS5YsmdawjDHGpCI9I/o2wCpVPXB+g4gEAh35883aP1HVGN/3g8BcoPHlhWqMMeZypCfRJzdybwlsVtXo5A4QkUIiUvj8z8AdwPrLCdQYY8zlSVMJBF+S/h2oqqrHL9g+Cfivqo6+YFtZYJyq3ikiVXGjeHA3fqeq6ptpOF8ssDu1/VJQAsiNK3zsunMXu+7cJS3XXUlVk533zpa1bq6EiETkxrX6dt25i1137nKl121PxhpjjJ+zRG+MMX7OHxP9WK8D8Ihdd+5i1527XNF1+90cvTHGmD/zxxG9McaYC1iiN8YYP+c3iV5EWovIFhHZLiLPeB1PZhKRCSJyUETWX7DtGhH5WkS2+b4X8zLGjCYiFURkmYhsFJENIjLIt92vrxtARPKLyHIRWeO79ld926uIyG++3/kZvjIlfkVE8ojIahFZ6Hvt99cMrry7iKwTkUgRifBtu+zfdb9I9L7yySNxZRpqAV1FpJa3UWWqSUDri7Y9A3yrqjWAb32v/UkCMERVawFNcHWTauH/1w0QB9ymqnVxJcNbi0gT4B1gmKpWB44CD3oXYqYZBGy64HVuuObzmqtqvQvWz1/277pfJHpc/ZztqhqlqueA6UA7j2PKNKr6A3Dkos3tgE98P38CtM/KmDKbqu5T1VW+n//A/c9fDj+/bgB1TvpeBvm+FFcafJZvu99du4iUB+4CxvleC35+zam47N91f0n05YA9F7yO9m3LTa5V1X2+n/cD13oZTGYSkcpAfeA3csl1+6YwIoGDwNfADlxXtwTfLv74Oz8c+DuQ5HtdHP+/5vOSK+9+2b/r1hzcD6mqiohfrpsVkauA2cATqnrCDfIcf75uVU0E6onI1bj6USHeRpS5RORu4KCqrhSRWz0Oxws3q2qMiJQCvhaRzRe+md7fdX8Z0ccAFS54Xd63LTc5ICJlAHzfD3ocT4YTkSBckv9MVef4Nvv9dV9IVY8By3A9m6/2lQoH//udvwlo6+s5PR03ZfMh/n3N/5NCeffL/l33l0S/AqjhuyOfF9cJa77HMWW1+UAv38+9gHkexpLhfPOz44FNqvrBBW/59XUDiEhJ30geESkA3I67R7EM6OTbza+uXVWfVdXyqloZ9//zd6raHT++5vMuUd79sn/X/ebJWBG5EzenlweYkJZyyDmViEwDbsWVLj0AvAx8AcwEKuJKPN+rqhffsM2xRORm4EdgHf8/Z/scbp7eb68bQETq4G6+5cENzmaq6mu+MuDTgWuA1UAPVY3zLtLM4Zu6eUpV784N15xSeXcRKc5l/q77TaI3xhiTPH+ZujHGGJMCS/TGGOPnLNEbY4yfs0RvjDF+zhK9Mcb4OUv0xhjj5yzRG2OMn/s/ZgfX1afaSkIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "loss = historyX.history['loss']\n",
    "val_loss = historyX.history['val_loss']\n",
    "acc = historyX.history['accuracy']\n",
    "val_acc = historyX.history['val_accuracy']\n",
    "x = range(len(acc))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(x, loss, 'b', label='loss')\n",
    "plt.plot(x, val_loss, 'g', label = 'val_loss' )\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(x, acc, 'b', label='acc')\n",
    "plt.plot(x, val_acc, 'g', label ='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "score = modelX.evaluate(x_valid, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
