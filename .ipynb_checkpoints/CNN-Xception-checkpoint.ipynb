{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "from PIL import Image\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.applications.xception import Xception\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "PATH = \"awe\"\n",
    "TRAIN_PATH = \"TrainData\"\n",
    "total_subjects = 100\n",
    "epochs = 20 \n",
    "img_size = 200\n",
    "          \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * 2 of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 4)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files belonging to 100 classes.\n",
      "Using 800 files for training.\n",
      "Found 1000 files belonging to 100 classes.\n",
      "Using 200 files for validation.\n"
     ]
    }
   ],
   "source": [
    "training_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"awe\\TrainData\",\n",
    "    labels='inferred',\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    validation_split=0.2,                                                             \n",
    "    batch_size=64,\n",
    "    image_size=(img_size, img_size))\n",
    "\n",
    "validation_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"awe\\TrainData\",\n",
    "    labels='inferred',\n",
    "    subset=\"validation\",\n",
    "    seed=64,\n",
    "    validation_split=0.2,                                                             \n",
    "    batch_size=128,\n",
    "    image_size=(img_size, img_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "# prefetch data\n",
    "training_dataset = training_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.5),\n",
    "    layers.experimental.preprocessing.RandomContrast(0.3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_filters = 64\n",
    "pool_size = 4\n",
    "kernel_size = 10\n",
    "input_shape = (img_size, img_size, 1)  # dimenstion\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.5),\n",
    "    layers.experimental.preprocessing.RandomContrast(0.3),\n",
    "    #data_augmentation,\n",
    "    layers.Conv2D(6,kernel_size,input_shape=input_shape, strides=1, activation='relu'), # conv 1\n",
    "    layers.AveragePooling2D(pool_size,strides=2),\n",
    "    layers.Conv2D(12,kernel_size,strides=1, activation='relu'), # conv 2\n",
    "    layers.AveragePooling2D(pool_size,strides=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(total_subjects),  # num_classes\n",
    "    layers.Activation('softmax') \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adadelta',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:755 train_step\n        loss = self.compiled_loss(\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 100) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4e2a7f6f3ca8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtraining_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 725\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    726\u001b[0m             *args, **kwds))\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:755 train_step\n        loss = self.compiled_loss(\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    c:\\users\\nejc\\desktop\\magistrska naloga\\notebooks\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 100) are incompatible\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    training_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    batch_size=70,\n",
    "    verbose=1,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "print(history.history)\n",
    "print('Train loss:', history.history['loss'])\n",
    "print('Train accuracy:', history.history['accuracy'])\n",
    "print('Test loss:', history.history['val_loss'])\n",
    "print('Test accuracy:', history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "x = range(len(acc))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(x, loss, 'b', label='loss')\n",
    "plt.plot(x, val_loss, 'g', label = 'val_loss' )\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(x, acc, 'b', label='acc')\n",
    "plt.plot(x, val_acc, 'g', label ='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "model.save_weights('weights.h4')\n",
    "\n",
    "score = model.evaluate(validation_dataset, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(mode): \n",
    "    total_images = []\n",
    "    label =[]\n",
    "    mode_path = os.path.join(PATH,mode)  # mode path -> awe/TrainData\n",
    "    subjects = os.listdir(mode_path)  # \n",
    "    \n",
    "    for subject in subjects:\n",
    "        image_path  = os.path.join(mode_path,subject)\n",
    "        images = os.listdir(image_path)\n",
    "        for image in images:\n",
    "            if(image.endswith(\".png\")):\n",
    "                file = os.path.join(image_path,image)\n",
    "                total_images.append(cv2.resize(cv2.imread(file),(200,200)))\n",
    "                label.append(int(subject))\n",
    "    total_images = np.array(total_images)\n",
    "    label = np.array(label)\n",
    "    return total_images , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,label = dataset('TrainData')\n",
    "\n",
    "def split_data(data,label,valid_len):\n",
    "    valid_len = int(valid_len*len(data)/100)\n",
    "    return (data[0:len(data)-valid_len],label[0:len(data)-valid_len],\n",
    "            data[len(data)-valid_len:len(data)],label[len(data)-valid_len:len(data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 200, 200, 3)\n",
      "(200, 200, 200, 3)\n",
      "(800,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_valid,y_valid = split_data(train,label,20)\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, total_subjects+1,dtype='int32')\n",
    "y_valid = keras.utils.to_categorical(y_valid, total_subjects+1,dtype='int32')\n",
    "y_train = y_train[:,0:total_subjects]\n",
    "y_valid = y_valid[:,0:total_subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 99, 99, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 99, 99, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 99, 99, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 97, 97, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 97, 97, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 97, 97, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 97, 97, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 97, 97, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 97, 97, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 97, 97, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 97, 97, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 49, 49, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 49, 49, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 49, 49, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 49, 49, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 49, 49, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 49, 49, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 49, 49, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 49, 49, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 49, 49, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 49, 49, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 25, 25, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 25, 25, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 25, 25, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 25, 25, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 25, 25, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 25, 25, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 25, 25, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 25, 25, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 25, 25, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 13, 13, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 13, 13, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 13, 13, 728)  2912        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 13, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 13, 13, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 13, 13, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 13, 13, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 13, 13, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 13, 13, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 13, 13, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 13, 13, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 13, 13, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 13, 13, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 13, 13, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 13, 13, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 13, 13, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 13, 13, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 13, 13, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 13, 13, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 13, 13, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 13, 13, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 13, 13, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 13, 13, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 13, 13, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 13, 13, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 13, 13, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 13, 13, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 13, 13, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 13, 13, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 13, 13, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 13, 13, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 13, 13, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 13, 13, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 13, 13, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 13, 13, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 13, 13, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 13, 13, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 13, 13, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 13, 13, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 13, 13, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 13, 13, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 13, 13, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 13, 13, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 13, 13, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 13, 13, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 13, 13, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 13, 13, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 13, 13, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 7, 7, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 1024)   4096        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          204900      global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 21,066,380\n",
      "Trainable params: 21,011,852\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_modelX = tf.keras.applications.Xception(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(x_train[0].shape))\n",
    "\n",
    "#base_modelX.trainable = False\n",
    "#inputs = keras.Input(shape=(img_size, img_size, 3))\n",
    "#x = base_modelX(inputs, training=False)\n",
    "\n",
    "x= base_modelX.output\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = keras.layers.Dense(total_subjects,activation='softmax')(x)\n",
    "\n",
    "modelX = keras.Model(base_modelX.input, outputs)\n",
    "modelX.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer in base_modelX.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelX.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12/12 [==============================] - 14s 518ms/step - loss: 65.4932 - accuracy: 0.0124 - val_loss: 60.6329 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 3s 226ms/step - loss: 66.7166 - accuracy: 0.0182 - val_loss: 60.4668 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 3s 226ms/step - loss: 65.5523 - accuracy: 0.0110 - val_loss: 60.2990 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 3s 226ms/step - loss: 65.5574 - accuracy: 0.0091 - val_loss: 60.1303 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 3s 226ms/step - loss: 66.2376 - accuracy: 0.0141 - val_loss: 59.9582 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 3s 226ms/step - loss: 66.6159 - accuracy: 0.0106 - val_loss: 59.7840 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 3s 227ms/step - loss: 65.7916 - accuracy: 0.0112 - val_loss: 59.6111 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 3s 228ms/step - loss: 64.4074 - accuracy: 0.0095 - val_loss: 59.4345 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 3s 228ms/step - loss: 63.2688 - accuracy: 0.0126 - val_loss: 59.2575 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 3s 229ms/step - loss: 65.1657 - accuracy: 0.0107 - val_loss: 59.0819 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 3s 228ms/step - loss: 63.7999 - accuracy: 0.0117 - val_loss: 58.9041 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 3s 229ms/step - loss: 62.5951 - accuracy: 0.0119 - val_loss: 58.7241 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 3s 229ms/step - loss: 63.9459 - accuracy: 0.0146 - val_loss: 58.5452 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 3s 229ms/step - loss: 63.4441 - accuracy: 0.0109 - val_loss: 58.3648 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 3s 230ms/step - loss: 61.8080 - accuracy: 0.0106 - val_loss: 58.1829 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 3s 231ms/step - loss: 62.2800 - accuracy: 0.0141 - val_loss: 58.0011 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 3s 230ms/step - loss: 63.7133 - accuracy: 0.0101 - val_loss: 57.8213 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 3s 231ms/step - loss: 61.7286 - accuracy: 0.0117 - val_loss: 57.6378 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 3s 231ms/step - loss: 62.0481 - accuracy: 0.0095 - val_loss: 57.4534 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 3s 230ms/step - loss: 62.7695 - accuracy: 0.0132 - val_loss: 57.2710 - val_accuracy: 0.0000e+00\n",
      "{'loss': [67.20020294189453, 66.90986633300781, 66.62043762207031, 66.33247375488281, 66.0450210571289, 65.75653839111328, 65.46737670898438, 65.1810531616211, 64.8932876586914, 64.60567474365234, 64.31996154785156, 64.03226470947266, 63.743812561035156, 63.45701599121094, 63.16849136352539, 62.87961959838867, 62.59073257446289, 62.304664611816406, 62.015106201171875, 61.72697448730469], 'accuracy': [0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.011250000447034836], 'val_loss': [60.63288116455078, 60.4667854309082, 60.299034118652344, 60.130332946777344, 59.958213806152344, 59.78404235839844, 59.61106491088867, 59.434505462646484, 59.25749206542969, 59.081886291503906, 58.904117584228516, 58.724082946777344, 58.54523468017578, 58.3647575378418, 58.1828727722168, 58.001121520996094, 57.821311950683594, 57.63780212402344, 57.45342254638672, 57.27097702026367], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
      "Train loss: [67.20020294189453, 66.90986633300781, 66.62043762207031, 66.33247375488281, 66.0450210571289, 65.75653839111328, 65.46737670898438, 65.1810531616211, 64.8932876586914, 64.60567474365234, 64.31996154785156, 64.03226470947266, 63.743812561035156, 63.45701599121094, 63.16849136352539, 62.87961959838867, 62.59073257446289, 62.304664611816406, 62.015106201171875, 61.72697448730469]\n",
      "Train accuracy: [0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.011250000447034836]\n",
      "Test loss: [60.63288116455078, 60.4667854309082, 60.299034118652344, 60.130332946777344, 59.958213806152344, 59.78404235839844, 59.61106491088867, 59.434505462646484, 59.25749206542969, 59.081886291503906, 58.904117584228516, 58.724082946777344, 58.54523468017578, 58.3647575378418, 58.1828727722168, 58.001121520996094, 57.821311950683594, 57.63780212402344, 57.45342254638672, 57.27097702026367]\n",
      "Test accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "historyX = modelX.fit(x_train, y_train,\n",
    "          batch_size=70,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_valid, y_valid))\n",
    "\n",
    "print(historyX.history)\n",
    "print('Train loss:', historyX.history['loss'])\n",
    "print('Train accuracy:', historyX.history['accuracy'])\n",
    "print('Test loss:', historyX.history['val_loss'])\n",
    "print('Test accuracy:', historyX.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "loss = historyX.history['loss']\n",
    "val_loss = historyX.history['val_loss']\n",
    "acc = historyX.history['accuracy']\n",
    "val_acc = historyX.history['val_accuracy']\n",
    "x = range(len(acc))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(x, loss, 'b', label='loss')\n",
    "plt.plot(x, val_loss, 'g', label = 'val_loss' )\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(x, acc, 'b', label='acc')\n",
    "plt.plot(x, val_acc, 'g', label ='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "score = modelX.evaluate(x_valid, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
