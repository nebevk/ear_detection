{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "from PIL import Image\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.applications.xception import Xception\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "PATH = \"awe\"\n",
    "TRAIN_PATH = \"TrainData\"\n",
    "total_subjects = 100\n",
    "epochs = 50 \n",
    "img_size = 200\n",
    "batch_size = 64\n",
    "          \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * 2 of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 2)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(mode): \n",
    "    total_images = []\n",
    "    label =[]\n",
    "    mode_path = os.path.join(PATH,mode)  # mode path -> awe/TrainData\n",
    "    subjects = os.listdir(mode_path)  # \n",
    "    \n",
    "    for subject in subjects:\n",
    "        image_path  = os.path.join(mode_path,subject)\n",
    "        images = os.listdir(image_path)\n",
    "        for image in images:\n",
    "            if(image.endswith(\".png\")):\n",
    "                file = os.path.join(image_path,image)\n",
    "                total_images.append(cv2.resize(cv2.imread(file),(200,200)))\n",
    "                label.append(int(subject))\n",
    "    total_images = np.array(total_images)\n",
    "    label = np.array(label)\n",
    "    return total_images , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,label = dataset('TrainData')\n",
    "\n",
    "def split_data(data,label,valid_len):\n",
    "    valid_len = int(valid_len*len(data)/100)\n",
    "    return (data[0:len(data)-valid_len],label[0:len(data)-valid_len],\n",
    "            data[len(data)-valid_len:len(data)],label[len(data)-valid_len:len(data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 200, 200, 3)\n",
      "(200, 200, 200, 3)\n",
      "(800,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_valid,y_valid = split_data(train,label,20)\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, total_subjects+1,dtype='int32')\n",
    "y_valid = keras.utils.to_categorical(y_valid, total_subjects+1,dtype='int32')\n",
    "y_train = y_train[:,0:total_subjects]\n",
    "y_valid = y_valid[:,0:total_subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 99, 99, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 99, 99, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 99, 99, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 97, 97, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 97, 97, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 97, 97, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 97, 97, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 97, 97, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 97, 97, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 97, 97, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 97, 97, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 49, 49, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 49, 49, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 49, 49, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 49, 49, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 49, 49, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 49, 49, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 49, 49, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 49, 49, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 49, 49, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 49, 49, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 25, 25, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 25, 25, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 25, 25, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 25, 25, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 25, 25, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 25, 25, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 25, 25, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 25, 25, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 25, 25, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 13, 13, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 13, 13, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 13, 13, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 13, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 13, 13, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 13, 13, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 13, 13, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 13, 13, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 13, 13, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 13, 13, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 13, 13, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 13, 13, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 13, 13, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 13, 13, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 13, 13, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 13, 13, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 13, 13, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 13, 13, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 13, 13, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 13, 13, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 13, 13, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 13, 13, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 13, 13, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 13, 13, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 13, 13, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 13, 13, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 13, 13, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 13, 13, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 13, 13, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 13, 13, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 13, 13, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 13, 13, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 13, 13, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 13, 13, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 13, 13, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 13, 13, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 13, 13, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 13, 13, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 13, 13, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 13, 13, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 13, 13, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 13, 13, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 13, 13, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 13, 13, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 13, 13, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 13, 13, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 13, 13, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 13, 13, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 13, 13, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 13, 13, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 13, 13, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 13, 13, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 13, 13, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 13, 13, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 13, 13, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 13, 13, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 13, 13, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          204900      global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 21,066,380\n",
      "Trainable params: 21,011,852\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_modelX = tf.keras.applications.Xception(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(x_train[0].shape))\n",
    "\n",
    "#base_modelX.trainable = False\n",
    "#inputs = keras.Input(shape=(img_size, img_size, 3))\n",
    "#x = base_modelX(inputs, training=False)\n",
    "\n",
    "x= base_modelX.output\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = keras.layers.Dense(total_subjects,activation='softmax')(x)\n",
    "\n",
    "modelX = keras.Model(base_modelX.input, outputs)\n",
    "modelX.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer in base_modelX.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelX.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 10s 423ms/step - loss: 73.7508 - accuracy: 0.0089 - val_loss: 58.4953 - val_accuracy: 0.0050\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 3s 230ms/step - loss: 72.2684 - accuracy: 0.0097 - val_loss: 58.3312 - val_accuracy: 0.0050\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 3s 216ms/step - loss: 72.7464 - accuracy: 0.0133 - val_loss: 58.1639 - val_accuracy: 0.0050\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 3s 216ms/step - loss: 72.1775 - accuracy: 0.0063 - val_loss: 57.9942 - val_accuracy: 0.0050\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 3s 217ms/step - loss: 71.9472 - accuracy: 0.0055 - val_loss: 57.8235 - val_accuracy: 0.0050\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 3s 217ms/step - loss: 71.3353 - accuracy: 0.0068 - val_loss: 57.6499 - val_accuracy: 0.0050\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 3s 217ms/step - loss: 72.2840 - accuracy: 0.0099 - val_loss: 57.4751 - val_accuracy: 0.0050\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 3s 218ms/step - loss: 68.8699 - accuracy: 0.0087 - val_loss: 57.2980 - val_accuracy: 0.0050\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 3s 218ms/step - loss: 72.3223 - accuracy: 0.0103 - val_loss: 57.1200 - val_accuracy: 0.0050\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 3s 219ms/step - loss: 70.9255 - accuracy: 0.0105 - val_loss: 56.9417 - val_accuracy: 0.0050\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 3s 219ms/step - loss: 68.5053 - accuracy: 0.0108 - val_loss: 56.7616 - val_accuracy: 0.0050\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 3s 219ms/step - loss: 71.2148 - accuracy: 0.0065 - val_loss: 56.5800 - val_accuracy: 0.0050\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 3s 219ms/step - loss: 69.8359 - accuracy: 0.0111 - val_loss: 56.3975 - val_accuracy: 0.0050\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 3s 219ms/step - loss: 70.2932 - accuracy: 0.0113 - val_loss: 56.2151 - val_accuracy: 0.0050\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 3s 219ms/step - loss: 70.0494 - accuracy: 0.0075 - val_loss: 56.0332 - val_accuracy: 0.0050\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 3s 220ms/step - loss: 68.9902 - accuracy: 0.0065 - val_loss: 55.8510 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 3s 220ms/step - loss: 68.4424 - accuracy: 0.0090 - val_loss: 55.6690 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 3s 220ms/step - loss: 67.0785 - accuracy: 0.0113 - val_loss: 55.4870 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 3s 220ms/step - loss: 67.0712 - accuracy: 0.0134 - val_loss: 55.3020 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 3s 220ms/step - loss: 66.0908 - accuracy: 0.0084 - val_loss: 55.1160 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 3s 221ms/step - loss: 67.2995 - accuracy: 0.0098 - val_loss: 54.9300 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 3s 221ms/step - loss: 67.0141 - accuracy: 0.0136 - val_loss: 54.7440 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 3s 221ms/step - loss: 67.7583 - accuracy: 0.0137 - val_loss: 54.5600 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 3s 221ms/step - loss: 68.0215 - accuracy: 0.0087 - val_loss: 54.3761 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 3s 221ms/step - loss: 65.5567 - accuracy: 0.0091 - val_loss: 54.1916 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 3s 221ms/step - loss: 66.2518 - accuracy: 0.0069 - val_loss: 54.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 3s 221ms/step - loss: 65.7554 - accuracy: 0.0188 - val_loss: 53.8240 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 3s 221ms/step - loss: 64.5907 - accuracy: 0.0108 - val_loss: 53.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 3s 222ms/step - loss: 63.9146 - accuracy: 0.0112 - val_loss: 53.4540 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 3s 222ms/step - loss: 64.8439 - accuracy: 0.0130 - val_loss: 53.2684 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 3s 221ms/step - loss: 63.6773 - accuracy: 0.0171 - val_loss: 53.0849 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 3s 222ms/step - loss: 63.0475 - accuracy: 0.0114 - val_loss: 52.9011 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 3s 222ms/step - loss: 65.0020 - accuracy: 0.0110 - val_loss: 52.7179 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 3s 222ms/step - loss: 63.0022 - accuracy: 0.0083 - val_loss: 52.5326 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 3s 222ms/step - loss: 62.7669 - accuracy: 0.0121 - val_loss: 52.3491 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 3s 223ms/step - loss: 63.7786 - accuracy: 0.0164 - val_loss: 52.1639 - val_accuracy: 0.0050\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 3s 222ms/step - loss: 63.6971 - accuracy: 0.0148 - val_loss: 51.9798 - val_accuracy: 0.0050\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 3s 222ms/step - loss: 61.7389 - accuracy: 0.0119 - val_loss: 51.7957 - val_accuracy: 0.0050\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 3s 223ms/step - loss: 61.4645 - accuracy: 0.0126 - val_loss: 51.6124 - val_accuracy: 0.0050\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 3s 223ms/step - loss: 61.1245 - accuracy: 0.0062 - val_loss: 51.4302 - val_accuracy: 0.0050\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 3s 222ms/step - loss: 62.4120 - accuracy: 0.0112 - val_loss: 51.2466 - val_accuracy: 0.0050\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 3s 223ms/step - loss: 60.1219 - accuracy: 0.0105 - val_loss: 51.0631 - val_accuracy: 0.0050\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 3s 223ms/step - loss: 60.4095 - accuracy: 0.0115 - val_loss: 50.8815 - val_accuracy: 0.0050\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 3s 222ms/step - loss: 60.3403 - accuracy: 0.0143 - val_loss: 50.6996 - val_accuracy: 0.0050\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 3s 223ms/step - loss: 58.9087 - accuracy: 0.0180 - val_loss: 50.5185 - val_accuracy: 0.0050\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 3s 223ms/step - loss: 60.8208 - accuracy: 0.0113 - val_loss: 50.3380 - val_accuracy: 0.0050\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 3s 223ms/step - loss: 59.9574 - accuracy: 0.0142 - val_loss: 50.1590 - val_accuracy: 0.0050\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 3s 223ms/step - loss: 58.6788 - accuracy: 0.0110 - val_loss: 49.9805 - val_accuracy: 0.0050\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 3s 223ms/step - loss: 59.3393 - accuracy: 0.0110 - val_loss: 49.8045 - val_accuracy: 0.0050\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 3s 223ms/step - loss: 57.5026 - accuracy: 0.0161 - val_loss: 49.6285 - val_accuracy: 0.0050\n",
      "{'loss': [73.21331787109375, 72.91532897949219, 72.6191635131836, 72.32344055175781, 72.025146484375, 71.72775268554688, 71.42855834960938, 71.12969970703125, 70.82888793945312, 70.52825927734375, 70.22598266601562, 69.92355346679688, 69.61992645263672, 69.31581115722656, 69.01139068603516, 68.70808410644531, 68.40343475341797, 68.0993423461914, 67.79405975341797, 67.48735046386719, 67.17896270751953, 66.8709945678711, 66.56265258789062, 66.25568389892578, 65.94917297363281, 65.64120483398438, 65.33248138427734, 65.02569580078125, 64.71863555908203, 64.41032409667969, 64.10321044921875, 63.798858642578125, 63.493927001953125, 63.191505432128906, 62.88923645019531, 62.58827590942383, 62.28634262084961, 61.98530197143555, 61.68647384643555, 61.389068603515625, 61.092472076416016, 60.79722213745117, 60.50237274169922, 60.20985412597656, 59.916534423828125, 59.62653732299805, 59.33699035644531, 59.04994583129883, 58.76389694213867, 58.48051834106445], 'accuracy': [0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.013749999925494194, 0.013749999925494194, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.013749999925494194, 0.013749999925494194, 0.013749999925494194, 0.013749999925494194, 0.013749999925494194, 0.013749999925494194, 0.013749999925494194, 0.012500000186264515, 0.012500000186264515], 'val_loss': [58.49529266357422, 58.331153869628906, 58.16386795043945, 57.994197845458984, 57.82353591918945, 57.64985275268555, 57.47506332397461, 57.29795837402344, 57.120033264160156, 56.941688537597656, 56.76164245605469, 56.5799560546875, 56.397518157958984, 56.215065002441406, 56.03315734863281, 55.850975036621094, 55.669044494628906, 55.48701477050781, 55.3019905090332, 55.1159553527832, 54.929954528808594, 54.74403762817383, 54.559959411621094, 54.37607955932617, 54.191612243652344, 54.0067138671875, 53.824031829833984, 53.6389274597168, 53.454017639160156, 53.268436431884766, 53.084861755371094, 52.9011116027832, 52.717864990234375, 52.53264236450195, 52.34910202026367, 52.163944244384766, 51.97980499267578, 51.79570388793945, 51.61244201660156, 51.430213928222656, 51.246639251708984, 51.063140869140625, 50.88145065307617, 50.69960021972656, 50.518524169921875, 50.33799743652344, 50.15898513793945, 49.9804801940918, 49.80454635620117, 49.628536224365234], 'val_accuracy': [0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291]}\n",
      "Train loss: [73.21331787109375, 72.91532897949219, 72.6191635131836, 72.32344055175781, 72.025146484375, 71.72775268554688, 71.42855834960938, 71.12969970703125, 70.82888793945312, 70.52825927734375, 70.22598266601562, 69.92355346679688, 69.61992645263672, 69.31581115722656, 69.01139068603516, 68.70808410644531, 68.40343475341797, 68.0993423461914, 67.79405975341797, 67.48735046386719, 67.17896270751953, 66.8709945678711, 66.56265258789062, 66.25568389892578, 65.94917297363281, 65.64120483398438, 65.33248138427734, 65.02569580078125, 64.71863555908203, 64.41032409667969, 64.10321044921875, 63.798858642578125, 63.493927001953125, 63.191505432128906, 62.88923645019531, 62.58827590942383, 62.28634262084961, 61.98530197143555, 61.68647384643555, 61.389068603515625, 61.092472076416016, 60.79722213745117, 60.50237274169922, 60.20985412597656, 59.916534423828125, 59.62653732299805, 59.33699035644531, 59.04994583129883, 58.76389694213867, 58.48051834106445]\n",
      "Train accuracy: [0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.009999999776482582, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.011250000447034836, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.013749999925494194, 0.013749999925494194, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.012500000186264515, 0.013749999925494194, 0.013749999925494194, 0.013749999925494194, 0.013749999925494194, 0.013749999925494194, 0.013749999925494194, 0.013749999925494194, 0.012500000186264515, 0.012500000186264515]\n",
      "Test loss: [58.49529266357422, 58.331153869628906, 58.16386795043945, 57.994197845458984, 57.82353591918945, 57.64985275268555, 57.47506332397461, 57.29795837402344, 57.120033264160156, 56.941688537597656, 56.76164245605469, 56.5799560546875, 56.397518157958984, 56.215065002441406, 56.03315734863281, 55.850975036621094, 55.669044494628906, 55.48701477050781, 55.3019905090332, 55.1159553527832, 54.929954528808594, 54.74403762817383, 54.559959411621094, 54.37607955932617, 54.191612243652344, 54.0067138671875, 53.824031829833984, 53.6389274597168, 53.454017639160156, 53.268436431884766, 53.084861755371094, 52.9011116027832, 52.717864990234375, 52.53264236450195, 52.34910202026367, 52.163944244384766, 51.97980499267578, 51.79570388793945, 51.61244201660156, 51.430213928222656, 51.246639251708984, 51.063140869140625, 50.88145065307617, 50.69960021972656, 50.518524169921875, 50.33799743652344, 50.15898513793945, 49.9804801940918, 49.80454635620117, 49.628536224365234]\n",
      "Test accuracy: [0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291, 0.004999999888241291]\n"
     ]
    }
   ],
   "source": [
    "historyX = modelX.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_valid, y_valid))\n",
    "\n",
    "print(historyX.history)\n",
    "print('Train loss:', historyX.history['loss'])\n",
    "print('Train accuracy:', historyX.history['accuracy'])\n",
    "print('Test loss:', historyX.history['val_loss'])\n",
    "print('Test accuracy:', historyX.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "loss = historyX.history['loss']\n",
    "val_loss = historyX.history['val_loss']\n",
    "acc = historyX.history['accuracy']\n",
    "val_acc = historyX.history['val_accuracy']\n",
    "x = range(len(acc))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(x, loss, 'b', label='loss')\n",
    "plt.plot(x, val_loss, 'g', label = 'val_loss' )\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(x, acc, 'b', label='acc')\n",
    "plt.plot(x, val_acc, 'g', label ='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "score = modelX.evaluate(x_valid, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
